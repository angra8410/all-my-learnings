# Actividad Interactiva â€” Observabilidad y Cost Management

ðŸŽ¯ Objetivo
Instrumentar un pipeline sencillo para exponer mÃ©tricas bÃ¡sicas (success/fail, duration, rows processed), crear una alerta y visualizar en un dashboard.

ðŸŸ¢ Ejercicio 1: AÃ±adir mÃ©tricas simples a un job (20 minutos)  
Objetivo: Exportar mÃ©tricas desde un script Python usando prometheus_client.

Ejemplo (snippet):
```python
from prometheus_client import Summary, Counter, start_http_server

REQUEST_TIME = Summary('job_duration_seconds', 'Time spent processing job')
ROWS_PROCESSED = Counter('rows_processed', 'Number of rows processed')

@REQUEST_TIME.time()
def run_job():
    # run ETL
    ROWS_PROCESSED.inc(1234)

if __name__ == '__main__':
    start_http_server(8000)
    run_job()
```

VerificaciÃ³n:
- `curl http://localhost:8000/metrics` -> observas `job_duration_seconds` y `rows_processed`.
- Resultado rows_processed: __

DuraciÃ³n: 20 minutos

ðŸ“Š Ejercicio 2: Crear alerta Prometheus (25 minutos)  
Objetivo: Definir una alert rule si job fails o duration > threshold.

Ejemplo rule (prometheus_rules.yml):
```yaml
groups:
- name: dataeng.rules
  rules:
  - alert: JobDurationHigh
    expr: job_duration_seconds_count > 0 and job_duration_seconds_sum / job_duration_seconds_count > 300
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Job duration is high"
```

VerificaciÃ³n:
- Cargar rule en Prometheus / simular mÃ©tricas -> alert fires? Yes / No

DuraciÃ³n: 25 minutos

ðŸ“ˆ Ejercicio 3: Dashboard simple en Grafana (30 minutos)  
Objetivo: Crear panel con job success rate, avg duration, rows processed.

Pasos:
1. AÃ±adir Prometheus como datasource en Grafana.
2. Crear panel con PromQL queries:
   - Success rate: `sum(increase(job_success_total[1h])) / sum(increase(job_runs_total[1h]))`
   - Avg duration: `rate(job_duration_seconds_sum[5m]) / rate(job_duration_seconds_count[5m])`

VerificaciÃ³n:
- Captura del panel: __ (pegar enlace o screenshot)

DuraciÃ³n: 30 minutos

ðŸ’¸ Ejercicio 4: Cost optimization checklist (30 minutos)  
Objetivo: Revisar configuraciÃ³n de cluster y proponer ajustes.

Checklist (prÃ¡ctico):
- Â¿Clusters auto-terminate configurados? Yes / No
- Â¿Uso de spot/preemptible nodes posible? Yes / No
- Â¿Cache / reuse data entre jobs? Yes / No
- Â¿Databricks delta cache o parquet pruning habilitado? Yes / No

VerificaciÃ³n: responde checklist y anota 3 acciones de ahorro estimadas con %.

DuraciÃ³n: 30 minutos

ðŸ“¦ Mini-proyecto (2 horas)  
Objetivo: Instrumentar un pipeline ETL con mÃ©tricas, crear un dashboard bÃ¡sico y una regla de alerting que notifique por Slack/Email cuando falla.

Entregables:
- script/metrics_exporter.py
- prometheus_rules.yml
- grafana_dashboard.json (o screenshot)
- runbook_observability.md (procedimiento de respuesta)

DuraciÃ³n: 2 horas
