# Módulo 04 — Spark (Scala) Fundamentals (Pareto 20/80)

Objetivo general:
Aprender el 20% de Spark/Scala que permite construir el 80% de pipelines: DataFrame API, particionamiento, writes idempotentes y tuning básico.

Resultados de aprendizaje:
- Escribir jobs Scala que lean CSV/Parquet y ejecuten transformaciones.
- Escribir tareas que respeten particionamiento y eviten collect().
- Ejemplos de optimizaciones: persist, broadcast joins, repartition.

Duración estimada: 12-16 horas

Pareto 20/80:
- 20%: DataFrame API, joins, repartition, write modes, avoiding collect
- 80%: practicar transformaciones, escribir jobs para datasets medianos, tuning y particionamiento

Estructura: ejercicios hands-on, ejemplo de job Scala, guía para ejecución en local o en Databricks.
