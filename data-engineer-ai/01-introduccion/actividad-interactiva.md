# Actividades Interactivas - MÃ³dulo 1: IntroducciÃ³n al Data Engineering para IA

## SecciÃ³n 1: Preguntas de OpciÃ³n MÃºltiple

### Pregunta 1
**Â¿CuÃ¡l es la responsabilidad principal de un Data Engineer?**

A) Crear modelos de Machine Learning  
B) DiseÃ±ar y mantener sistemas que recolectan, almacenan y procesan datos  
C) Hacer anÃ¡lisis estadÃ­stico y visualizaciones  
D) Gestionar bases de datos Ãºnicamente

**Tu respuesta**: ___

---

### Pregunta 2
**Â¿QuÃ© significa ETL?**

A) Execute, Test, Load  
B) Extract, Transform, Load  
C) Evaluate, Train, Learn  
D) Export, Transfer, Link

**Tu respuesta**: ___

---

### Pregunta 3
**Â¿CuÃ¡l es la diferencia principal entre Data Warehouse y Data Lake?**

A) Data Warehouse es mÃ¡s caro que Data Lake  
B) Data Warehouse almacena datos estructurados con esquema definido, Data Lake almacena datos raw en cualquier formato  
C) Data Lake es solo para big data, Data Warehouse para datos pequeÃ±os  
D) No hay diferencia real, son tÃ©rminos intercambiables

**Tu respuesta**: ___

---

### Pregunta 4
**Â¿QuÃ© caracteriza al procesamiento en tiempo real (streaming)?**

A) Procesa grandes volÃºmenes una vez al dÃ­a  
B) Procesa datos continuamente a medida que llegan  
C) Es mÃ¡s barato que procesamiento batch  
D) Solo funciona con Apache Spark

**Tu respuesta**: ___

---

### Pregunta 5
**Â¿CuÃ¡l de estas herramientas NO es tÃ­picamente usada por Data Engineers?**

A) Apache Airflow  
B) SQL  
C) Adobe Photoshop  
D) Pandas

**Tu respuesta**: ___

---

### Pregunta 6
**Â¿QuÃ© es un Lakehouse?**

A) Una casa junto a un lago donde trabajan data engineers  
B) Una combinaciÃ³n de Data Lake y Data Warehouse  
C) Un tipo de base de datos NoSQL  
D) Una versiÃ³n antigua de Data Lake

**Tu respuesta**: ___

---

### Pregunta 7
**Â¿QuÃ© porcentaje del tiempo de un Data Engineer tÃ­picamente se dedica a preparaciÃ³n de datos?**

A) 20%  
B) 40%  
C) 60%  
D) 80%

**Tu respuesta**: ___

---

### Pregunta 8
**Â¿CuÃ¡l es la funciÃ³n principal de Apache Airflow?**

A) Procesar big data  
B) Orquestar y programar workflows de datos  
C) Almacenar datos  
D) Crear visualizaciones

**Tu respuesta**: ___

---

## SecciÃ³n 2: Verdadero o Falso

Marca V (Verdadero) o F (Falso) para cada afirmaciÃ³n:

1. **Un Data Engineer y un Data Scientist hacen exactamente el mismo trabajo.** ___

2. **SQL es un lenguaje esencial para Data Engineers.** ___

3. **Los Data Engineers solo trabajan con datos estructurados.** ___

4. **Los sistemas de IA modernos pueden funcionar sin Data Engineers.** ___

5. **Procesamiento batch es siempre mejor que streaming.** ___

6. **Python es el lenguaje mÃ¡s usado en Data Engineering.** ___

7. **Data quality es responsabilidad Ãºnicamente del equipo de QA.** ___

8. **Los pipelines de datos necesitan ser monitoreados continuamente.** ___

---

## SecciÃ³n 3: Relaciona Conceptos

Conecta cada tÃ©rmino con su descripciÃ³n correcta:

**TÃ©rminos:**
1. Data Lake
2. Apache Airflow
3. ETL
4. Data Warehouse
5. Streaming

**Descripciones:**
A) Orquestador de workflows de datos  
B) AlmacÃ©n de datos estructurados optimizado para anÃ¡lisis  
C) Procesamiento de datos en tiempo real  
D) Almacenamiento de datos raw en cualquier formato  
E) Extract, Transform, Load

**Tus respuestas:**
1 â†’ ___ | 2 â†’ ___ | 3 â†’ ___ | 4 â†’ ___ | 5 â†’ ___

---

## SecciÃ³n 4: Completar el CÃ³digo

### Ejercicio 1
Completa el pipeline ETL bÃ¡sico:

```python
import pandas as pd

def extract():
    """Extrae datos de una fuente"""
    data = {
        'nombre': ['Ana', 'Luis', 'MarÃ­a'],
        'edad': [25, 30, 28]
    }
    df = ___________(data)  # Completa aquÃ­
    return df

def transform(df):
    """Agrega una columna calculada"""
    df['edad_en_5_aÃ±os'] = df['edad'] + ___  # Completa aquÃ­
    return df

def load(df):
    """Guarda los datos"""
    df.to_csv('_________.csv', index=False)  # Completa el nombre
    print("Datos guardados")

# Ejecutar pipeline
raw_data = extract()
clean_data = transform(raw_data)
load(clean_data)
```

---

### Ejercicio 2
Completa la validaciÃ³n de datos:

```python
def validate_email(email: str) -> bool:
    """Valida que un email sea vÃ¡lido"""
    return '___' in email and '.' in email  # Completa aquÃ­

def clean_data(df):
    """Limpia DataFrame eliminando valores nulos"""
    return df.________()  # Completa con mÃ©todo de pandas

# Test
assert validate_email("user@example.com") == True
assert validate_email("invalid-email") == ___  # Completa aquÃ­
```

---

## SecciÃ³n 5: AnÃ¡lisis de Casos

### Caso 1: E-commerce en Crecimiento

**Contexto:**
Una tienda online procesa 10,000 pedidos diarios. Necesitan:
- Reportes de ventas actualizados cada noche
- DetecciÃ³n de fraude en tiempo real
- Recomendaciones de productos

**Preguntas:**

1. **Â¿QuÃ© tipo de procesamiento usarÃ­as para los reportes de ventas?**
   - [ ] Batch (una vez al dÃ­a)
   - [ ] Streaming (tiempo real)
   
   **Justifica**: ___________________________________________

2. **Â¿Y para detecciÃ³n de fraude?**
   - [ ] Batch
   - [ ] Streaming
   
   **Justifica**: ___________________________________________

3. **Â¿QuÃ© tecnologÃ­as recomendarÃ­as para cada necesidad?**
   - Reportes: ___________________________________________
   - Fraude: ___________________________________________
   - Recomendaciones: ___________________________________________

---

### Caso 2: Sistema RAG para DocumentaciÃ³n

**Contexto:**
Una empresa quiere crear un chatbot que responda preguntas sobre sus manuales tÃ©cnicos (1000+ documentos PDF).

**Preguntas:**

1. **Â¿QuÃ© pasos del pipeline de datos son necesarios?**
   
   Ordena del 1 al 6:
   - [ ] Generar embeddings
   - [ ] Extraer texto de PDFs
   - [ ] Almacenar en base vectorial
   - [ ] Dividir texto en chunks
   - [ ] Limpiar y normalizar texto
   - [ ] Implementar bÃºsqueda semÃ¡ntica

2. **Â¿QuÃ© rol juega el Data Engineer aquÃ­?**
   
   ___________________________________________
   ___________________________________________

3. **Â¿Batch o streaming para este caso?**
   
   ___________________________________________

---

## SecciÃ³n 6: DiseÃ±o de Arquitectura

### Ejercicio: Tu Primer DiseÃ±o

**Escenario:**
DiseÃ±a una arquitectura simple para este caso:

**Requisito**: Una app de anÃ¡lisis de redes sociales que:
1. Recolecta tweets sobre un tema cada hora
2. Analiza sentimiento (positivo/negativo)
3. Genera dashboard con tendencias

**Tu diseÃ±o (dibuja o describe):**

```
INGESTA:
Â¿De dÃ³nde vienen los datos?
___________________________________________

ALMACENAMIENTO:
Â¿DÃ³nde los guardas?
___________________________________________

PROCESAMIENTO:
Â¿CÃ³mo los procesas?
___________________________________________

VISUALIZACIÃ“N:
Â¿CÃ³mo los muestras?
___________________________________________

HERRAMIENTAS:
Â¿QuÃ© tecnologÃ­as usarÃ­as?
___________________________________________
```

---

## SecciÃ³n 7: Ejercicios PrÃ¡cticos de CÃ³digo

### Ejercicio 1: Pipeline ETL Completo

**Tarea**: Crea un pipeline que procese datos de ventas.

**Archivo**: `ventas_etl.py`

```python
import pandas as pd
from datetime import datetime

# Datos de ejemplo
ventas_raw = {
    'fecha': ['2024-01-01', '2024-01-02', '2024-01-01'],
    'producto': ['laptop', 'MOUSE', 'Teclado  '],
    'precio': [1000, 25, None],
    'cantidad': [2, 10, 5]
}

# TODO: Implementa las siguientes funciones

def extract_data(data_dict):
    """Convierte dict a DataFrame"""
    # Tu cÃ³digo aquÃ­
    pass

def transform_data(df):
    """
    Aplica las siguientes transformaciones:
    1. Normalizar nombres de productos (lowercase, sin espacios extra)
    2. Llenar precios None con 0
    3. Calcular columna 'total' = precio * cantidad
    4. Convertir fecha a datetime
    """
    # Tu cÃ³digo aquÃ­
    pass

def validate_data(df):
    """
    Valida que:
    1. No hay precios negativos
    2. Cantidad es mayor que 0
    3. Producto no es string vacÃ­o
    Retorna True si pasa todas las validaciones
    """
    # Tu cÃ³digo aquÃ­
    pass

def load_data(df, filename='ventas_clean.csv'):
    """Guarda en CSV"""
    # Tu cÃ³digo aquÃ­
    pass

# Ejecutar pipeline completo
if __name__ == "__main__":
    # Tu cÃ³digo aquÃ­
    pass
```

**Bonus**: Agrega logging para saber quÃ© hace cada paso.

---

### Ejercicio 2: AnÃ¡lisis de Logs

**Tarea**: Procesa logs de una aplicaciÃ³n web.

**Archivo**: `log_processor.py`

```python
import pandas as pd

# Logs de ejemplo
logs = """
2024-01-15 10:30:15 INFO User login successful - user_id: 123
2024-01-15 10:30:20 ERROR Database connection failed - retrying...
2024-01-15 10:30:45 INFO User 456 viewed product page
2024-01-15 10:31:10 WARNING High memory usage: 85%
2024-01-15 10:31:25 INFO Purchase completed - order_id: 789
"""

# TODO: Implementa
def parse_logs(log_string):
    """
    Convierte logs a DataFrame con columnas:
    - timestamp
    - level (INFO, ERROR, WARNING)
    - message
    """
    # Tu cÃ³digo aquÃ­
    pass

def analyze_logs(df):
    """
    Calcula:
    - Total de logs por nivel
    - NÃºmero de errores
    - Primera y Ãºltima entrada
    """
    # Tu cÃ³digo aquÃ­
    pass

# Ejecutar
if __name__ == "__main__":
    # Tu cÃ³digo aquÃ­
    pass
```

---

### Ejercicio 3: ConfiguraciÃ³n de Entorno

**Tarea**: Configura tu entorno de desarrollo completo.

**Checklist tÃ©cnico:**
- [ ] Python 3.10+ instalado
- [ ] Entorno virtual creado
- [ ] pandas, numpy, jupyter instalados
- [ ] Docker instalado y funcionando
- [ ] Git configurado
- [ ] Cuenta GitHub creada
- [ ] Cuenta AWS Free Tier creada (opcional para mÃ³dulos futuros)

**Verifica tu setup:**

```bash
# Crea archivo verify_setup.py
python verify_setup.py
```

```python
# verify_setup.py
import sys

def check_python_version():
    version = sys.version_info
    if version.major >= 3 and version.minor >= 10:
        print("âœ… Python version OK:", sys.version)
    else:
        print("âŒ Python version too old. Need 3.10+")

def check_packages():
    required = ['pandas', 'numpy', 'requests']
    for package in required:
        try:
            __import__(package)
            print(f"âœ… {package} installed")
        except ImportError:
            print(f"âŒ {package} NOT installed")

if __name__ == "__main__":
    print("ğŸ” Verificando setup...\n")
    check_python_version()
    check_packages()
    print("\nâœ¨ VerificaciÃ³n completa!")
```

---

## SecciÃ³n 8: InvestigaciÃ³n y Pensamiento CrÃ­tico

### Pregunta 1: InvestigaciÃ³n de Herramientas

**Tarea**: Investiga y compara dos orquestadores.

| CaracterÃ­stica | Apache Airflow | Prefect |
|----------------|----------------|---------|
| AÃ±o de creaciÃ³n | ___ | ___ |
| Lenguaje | ___ | ___ |
| Ventajas | ___ | ___ |
| Desventajas | ___ | ___ |
| Casos de uso ideales | ___ | ___ |

**Â¿CuÃ¡l elegirÃ­as para un proyecto personal y por quÃ©?**
___________________________________________
___________________________________________

---

### Pregunta 2: AnÃ¡lisis de Arquitectura Real

**Tarea**: Investiga la arquitectura de datos de Netflix.

1. **Â¿QuÃ© problemas de datos tiene Netflix?**
   ___________________________________________

2. **Â¿QuÃ© tecnologÃ­as usa?** (Investiga en internet)
   ___________________________________________

3. **Â¿Batch o streaming?**
   ___________________________________________

4. **Â¿QuÃ© puedes aprender de su arquitectura?**
   ___________________________________________

---

### Pregunta 3: Tu Caso de Uso

**Piensa en un proyecto personal que te gustarÃ­a hacer.**

**Describe:**
1. **Â¿QuÃ© problema resuelve?**
   ___________________________________________

2. **Â¿QuÃ© datos necesitas?**
   ___________________________________________

3. **Â¿De dÃ³nde vienen esos datos?**
   ___________________________________________

4. **Â¿CÃ³mo los procesarÃ­as?** (Describe tu pipeline)
   ___________________________________________

5. **Â¿QuÃ© herramientas usarÃ­as?**
   ___________________________________________

---

## SecciÃ³n 9: DesafÃ­o del MÃ³dulo ğŸ†

### Proyecto Mini: Pipeline de Datos MeteorolÃ³gicos

**Objetivo**: Crear un pipeline ETL que procese datos del clima.

**Requisitos:**

1. **Extract**: Usar API pÃºblica del clima (ejemplo: OpenWeatherMap)
2. **Transform**: 
   - Convertir temperatura de Kelvin a Celsius
   - Extraer fecha/hora
   - Calcular promedio, mÃ¡xima, mÃ­nima del dÃ­a
3. **Load**: Guardar en CSV con formato limpio
4. **Bonus**: Generar grÃ¡fico simple de temperatura

**Estructura sugerida:**

```python
# weather_pipeline.py
import requests
import pandas as pd
from datetime import datetime

API_KEY = "tu_api_key"  # Obtener de openweathermap.org
CITY = "Madrid"

def extract_weather_data(city, api_key):
    """Llama a la API y obtiene datos"""
    # Tu cÃ³digo aquÃ­
    pass

def transform_weather_data(raw_data):
    """Transforma y limpia los datos"""
    # Tu cÃ³digo aquÃ­
    pass

def load_weather_data(df, filename):
    """Guarda en CSV"""
    # Tu cÃ³digo aquÃ­
    pass

def run_pipeline():
    """Ejecuta el pipeline completo"""
    print("ğŸŒ¤ï¸ Iniciando pipeline meteorolÃ³gico...")
    # Tu cÃ³digo aquÃ­
    pass

if __name__ == "__main__":
    run_pipeline()
```

**Criterios de Ã©xito:**
- [ ] Pipeline se ejecuta sin errores
- [ ] Datos se guardan correctamente
- [ ] Transformaciones aplicadas
- [ ] CÃ³digo comentado
- [ ] Manejo bÃ¡sico de errores

---

## AutoevaluaciÃ³n

### Â¿CuÃ¡ntas preguntas/ejercicios completaste?

- OpciÃ³n mÃºltiple (1-8): ___ / 8
- Verdadero/Falso (1-8): ___ / 8
- Relacionar conceptos: ___ / 5
- Completar cÃ³digo: ___ / 2
- AnÃ¡lisis de casos: ___ / 2
- Ejercicios prÃ¡cticos: ___ / 3
- InvestigaciÃ³n: ___ / 3
- DesafÃ­o del mÃ³dulo: ___ / 1

**Total**: ___ / 32

### ReflexiÃ³n

**Lo que mejor entendÃ­:**
___________________________________________
___________________________________________

**Lo que mÃ¡s me costÃ³:**
___________________________________________
___________________________________________

**Preguntas que me quedaron:**
___________________________________________
___________________________________________

**Tiempo dedicado al mÃ³dulo:** ___ horas

---

**Siguiente paso**: Revisa [retroalimentacion.md](retroalimentacion.md) para ver las soluciones y explicaciones, luego registra tu progreso en [progreso.md](progreso.md).

**Â¡Excelente trabajo! ğŸ‰**
