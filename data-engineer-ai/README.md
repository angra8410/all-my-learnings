# Data Engineer para Sistemas AI (RAG, AWS, Pipelines)

## Introducción

¡Bienvenido al curso de Data Engineering para Sistemas de Inteligencia Artificial! Este curso está diseñado para llevarte desde los fundamentos hasta la implementación de sistemas de datos modernos que alimentan aplicaciones de IA, incluyendo RAG (Retrieval Augmented Generation), pipelines de datos en AWS, y sistemas de ML en producción.

## ¿Para quién es este curso?

Este curso es ideal para:
- **Desarrolladores** que quieren especializarse en Data Engineering para IA
- **Científicos de datos** que buscan entender la infraestructura de producción
- **Ingenieros de software** interesados en sistemas de datos y ML
- **Profesionales de TI** que desean trabajar con AWS y arquitecturas de datos modernas

## ¿Qué aprenderás?

Al finalizar este curso, serás capaz de:

- ✅ Diseñar y construir **pipelines ETL/ELT** robustos y escalables
- ✅ Implementar sistemas **RAG (Retrieval Augmented Generation)** con bases de datos vectoriales
- ✅ Trabajar con **AWS Bedrock** y servicios de IA en la nube
- ✅ Crear **pipelines de ML** con seguimiento de experimentos y versionado de modelos
- ✅ Ingestar y procesar **documentos** de múltiples formatos
- ✅ Aplicar **buenas prácticas** de ingeniería de datos
- ✅ Colaborar en **equipos internacionales** con inglés técnico
- ✅ Desarrollar un **proyecto integrador** completo

## Estructura del Curso

El curso está organizado en 9 módulos progresivos:

### [Módulo 1: Introducción](01-introduccion/)
Fundamentos de Data Engineering, arquitecturas de datos modernas, y el rol del Data Engineer en sistemas de IA.

### [Módulo 2: ETL Pipelines](02-etl-pipelines/)
Diseño e implementación de pipelines ETL/ELT, orquestación con Apache Airflow, y mejores prácticas.

### [Módulo 3: Ingesta de Documentos](03-ingesta-documentos/)
Procesamiento de múltiples formatos (PDF, Word, HTML), extracción de texto, chunking y preprocesamiento.

### [Módulo 4: RAG y Sistemas Agentic](04-rag-agentic/)
Implementación de sistemas RAG, bases de datos vectoriales, embeddings, y arquitecturas agentic.

### [Módulo 5: AWS Bedrock](05-aws-bedrock/)
Servicios de IA en AWS, modelos foundation, integración con Bedrock, y arquitecturas serverless.

### [Módulo 6: ML Pipelines y Experiments](06-ml-pipelines-experiments/)
Pipelines de Machine Learning, MLflow, versionado de modelos, y gestión de experimentos.

### [Módulo 7: Buenas Prácticas](07-buenas-practicas/)
Testing, monitoring, logging, CI/CD para pipelines de datos, y data quality.

### [Módulo 8: Colaboración e Inglés](08-colaboracion-ingles/)
Inglés técnico para Data Engineering, documentación, code reviews, y trabajo en equipos distribuidos.

### [Módulo 9: Proyecto Integrador](09-proyecto-integrador/)
Desarrollo de un sistema completo que integra todos los conceptos del curso.

## Prerrequisitos

### Conocimientos Recomendados:
- Programación básica en **Python**
- Conceptos básicos de **bases de datos** (SQL)
- Familiaridad con **línea de comandos**
- Git básico para control de versiones

### No necesitas experiencia previa en:
- AWS o cloud computing
- Machine Learning
- Data Engineering
- Sistemas de IA

## Metodología de Aprendizaje

Cada módulo incluye:

1. **README.md**: Teoría clara y concisa con ejemplos prácticos
2. **actividad-interactiva.md**: Ejercicios prácticos y desafíos
3. **progreso.md**: Plantilla para registrar tu avance personal
4. **retroalimentacion.md**: Soluciones y explicaciones detalladas
5. **"De open source a enterprise"**: Comparativa de herramientas y transferencia de habilidades

## Tecnologías y Herramientas

A lo largo del curso trabajarás con:

**Lenguajes:**
- Python (primario)
- SQL

**Procesamiento de Datos:**
- Pandas, Polars
- Apache Spark (intro)
- dbt (data build tool)

**Orquestación:**
- Apache Airflow
- AWS Step Functions

**Bases de Datos:**
- PostgreSQL
- Amazon RDS
- Redis
- Pinecone / Chroma / Weaviate (vectoriales)

**IA y ML:**
- LangChain
- AWS Bedrock
- OpenAI API
- Hugging Face
- MLflow

**Cloud (AWS):**
- S3
- Lambda
- Glue
- Bedrock
- SageMaker (intro)

**DevOps:**
- Docker
- GitHub Actions
- Terraform (intro)

## Tiempo Estimado

- **Módulos 1-8**: 8-10 semanas (10-12 horas/semana)
- **Módulo 9 (Proyecto)**: 2-3 semanas
- **Total**: 10-13 semanas aprox.

## Cómo Usar Este Curso

1. **Sigue el orden sugerido**: Los módulos están diseñados progresivamente
2. **Practica activamente**: Haz todos los ejercicios y desafíos
3. **Registra tu progreso**: Usa los archivos `progreso.md`
4. **Consulta las retroalimentaciones**: Aprende de las soluciones explicadas
5. **Construye tu portfolio**: Documenta tus proyectos en GitHub

## Plan de Estudio Sugerido

Consulta el archivo [plan-estudio.md](plan-estudio.md) para una ruta de aprendizaje detallada con checklists, recursos recomendados y objetivos semanales.

## Recursos Adicionales

- **Documentación oficial**: AWS, Python, LangChain
- **Libros recomendados**: "Designing Data-Intensive Applications"
- **Comunidades**: r/dataengineering, AWS Community
- **Certificaciones**: AWS Certified Data Analytics, Machine Learning

## Filosofía del Curso

> "El mejor Data Engineer no es el que conoce todas las herramientas, sino el que sabe cuándo y por qué usar cada una."

Este curso enfatiza:
- 🎯 **Entendimiento profundo** sobre memorización
- 🛠️ **Proyectos prácticos** sobre teoría abstracta
- 🔄 **Iteración y mejora** continua
- 🌍 **Perspectiva real** del trabajo profesional
- 🚀 **Preparación para producción**, no solo demos

## Contribuciones y Feedback

Este es un material de aprendizaje personal en constante evolución. Si encuentras errores, tienes sugerencias o quieres compartir tu experiencia, ¡toda retroalimentación es bienvenida!

---

**¿Listo para comenzar?** 

Empieza por el [Módulo 1: Introducción](01-introduccion/) y descubre el fascinante mundo del Data Engineering para IA.

**¡Mucha suerte en tu viaje de aprendizaje!** 🚀📊🤖
